{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "EEG_ESI_Practical-1",
      "provenance": [],
      "collapsed_sections": [
        "b768a2be",
        "a6c932c7",
        "f159f0b2",
        "4dd7362b",
        "2b947c8d",
        "8b89c87d",
        "346c4ab8",
        "3bbaa7bc",
        "d384b10e",
        "5c8cc7bf",
        "db85b766",
        "7a2f3382",
        "7b15eed7"
      ],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GitEmmSt/NeuroEngineering_Science/blob/MainNeuro/EEG_ESI_Practical_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "921219a1"
      },
      "source": [
        "# Neuro-engineering Science\n",
        "\n",
        "# Practical Session: EEG Source Localization\n",
        "***\n",
        "*prof. Pieter van Mierlo* <br>\n",
        "*Emma Christiaen, Emma Depuydt, Jolan Heyse, Gert Vanhollebeke* <br><br>\n",
        "*Medical Image and Signal Processing (MEDISIP)* <br>\n",
        "*Ghent University Hospital, C. Heymanslaan 10, 9000 Gent, Belgium*"
      ],
      "id": "921219a1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cd02f9a"
      },
      "source": [
        "<font color=blue>Student names and IDs: </font>"
      ],
      "id": "2cd02f9a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f66c3811"
      },
      "source": [
        "### Practical info\n",
        "This practical session is about EEG source localization. Background documentation about this subject can be found in the course notes. The necessary files for the exercises can be downloaded from Ufora. We expect you to hand in the notebook with your code together with the figures via Ufora. The deadline for submission is ***03/11/2021 at 11.59pm***.\n",
        "\n",
        "### Required modules\n",
        "During this practical session the following libraries will be used:\n",
        "- [__Numpy__](https://docs.scipy.org/doc/numpy-dev/user/quickstart.html): library used for scientific computing containing N-dimensional arrays, functions and Fourier transform.\n",
        "- [__MNE__](https://mne.tools/stable/index.html): open-source external library for exploring, visualizing, and analyzing human neurophysiological data.\n",
        "- [__Nibabel__](https://nipy.org/nibabel/): package used for read/write access to some common medical and neuroimaging file formats\n",
        "- [__nilearn__](https://nilearn.github.io/#): library for statistical analysis for neuroimaging in Python, also provides different plotting functions.\n",
        "- [__niwidgets__](http://nipy.org/niwidgets/): package that provides easy and general wrappers to display interactive widgets that visualise standard-format neuroimaging data, using new functions and standard functions from other libraries\n",
        "\n",
        "Any external library can be included in the beginning of the code with the **import** statement, followed by the name of the library.<br>\n",
        "If the library is not yet installed in your Anaconda Navigator or Python environment, simply type in your terminal: *conda install package_name* or *pip install package_name*."
      ],
      "id": "f66c3811"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cbde9fe"
      },
      "source": [
        "# pip install mne\n",
        "# pip install nibabel\n",
        "# pip install -U --user nilearn\n",
        "# pip install niwidgets\n",
        "# pip install pyvistaqt"
      ],
      "id": "3cbde9fe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67e6711a"
      },
      "source": [
        "In order to have enough background to solve and understand the tasks in this practical session, we have summarized the theory on EEG source imaging (ESI) below.\n",
        "\n",
        "## 1. What are we measuring with EEG?\n",
        "\n",
        "Approximately 100.000 neurons are needed to be simultaneously active to generate measurable EEG signals. Pyramidal neuron cells located inside gray matter are the main direct sources of EEG signals. We model the synaptic currents of these pyramidal cells with the electrical current dipole characterized by a location, intensity and orientation.\n",
        "\n",
        "<img src=\"./Figures/WAWM.JPG\" alt=\"Fig 1\" width=\"600px\">\n",
        "\n",
        "## 2. Forward model\n",
        "\n",
        "In order to be able to reconstruct the generating sources of EEG signals we need a forward model. The forward model contains information about: \n",
        "- The head model\n",
        "- The source space\n",
        "\n",
        "<img src=\"./Figures/Forwardmodel.png\" alt=\"Fig 2\" width=\"600px\">\n",
        "\n",
        "### 2.1 The head model\n",
        "\n",
        "The head model contains the geometrical and electromagnetic properties of the head. It also contains the locations of the electrodes. In practice, a head model is constructed based on the segmentation into different tissue types (scalp, skull, cerebrospinal fluid (CSF), gray and white matter) of an anatomical MR image and subsequently coregistering the electrode positions on this head model.\n",
        "\n",
        "<img src=\"./Figures/HeadModel.JPG\" alt=\"Fig 3\" width=\"500px\">\n",
        "\n",
        "### 2.2 The source space\n",
        "\n",
        "#### Single dipole\n",
        "There are several types of source spaces we can use in order to describe the measured EEG data in the forward model. For example based on a single dipole located in the gray matter:\n",
        "\n",
        "\\begin{equation*}\n",
        "\\textbf{V}=\\mathbf{L(r)d(r)} + \\epsilon\n",
        "\\label{eq:sd} \\tag{1}\n",
        "\\end{equation*}\n",
        "\n",
        "where $\\textbf{V} \\in \\mathbb{R}^{K \\times 1}$ is a set of electrode potentials ($K$ is the number of channels) caused by $\\textbf{d} \\in \\mathbb{R}^{3 \\times 1}$, the dipole location in 3 orthogonal directions on location $\\textbf{r}$ inside the gray matter. $\\mathbf{L(r)} \\in \\mathbb{R}^{K \\times 3}$ is a lead field matrix which represents the headmodel properties (geometry, electrode locations, conductivities) and varies depending on the dipole location $\\textbf{r}$.  $\\epsilon$ is the sensor noise. \n",
        "\n",
        "#### Multiple dipoles\n",
        "We can also assume multiple dipoles located inside the gray matter to model the EEG measurements:\n",
        "\n",
        "\\begin{equation*}\n",
        "\\textbf{V}=\\mathbf{L(r_{1})d(r_{1}) + L(r_{1})d(r_{1}) + \\dots + L(r_{p})d(r_{p})} + \\epsilon\n",
        "\\label{eq:md} \\tag{2}\n",
        "\\end{equation*}\n",
        "\n",
        "With P the number of dipoles on locations $\\mathbf{r_{1}}, \\mathbf{r_{2}}, \\dots \\mathbf{r_{P}}$ inside the gray matter. \n",
        "\n",
        "#### Distributed dipoles\n",
        "Finally, we can also assume to represent the EEG measurements with a distributed source model:\n",
        "\n",
        "\\begin{equation*}\n",
        "\\textbf{V} = \\textbf{L}.\\textbf{D} + \\epsilon\n",
        "\\label{eq:dd} \\tag{3}\n",
        "\\end{equation*}\n",
        "\n",
        "With $\\textbf{D} \\in \\mathbb{R}^{3N \\times 1}$, the amplitude of $N$ current dipoles distributed in the brain with fixed locations (typically more than 1000) in 3 orthogonal directions. $\\textbf{L} \\in \\mathbb{R}^{K \\times 3N}$ is the lead field matrix linking the source amplitudes in $\\textbf{D}$ to the electrical scalp potentials in $\\textbf{V}$. \n",
        "\n",
        "## 3. Inverse problem\n",
        "\n",
        "The forward model describes what EEG signals we would measure when a given source in the brain is active. However, we are interested in doing this the other way around: we know the measured EEG and we want to deduce the sources in the brain generating that EEG. For this, we have to solve the inverse problem. Several techniques exist to solve the inverse problem in order to get a unique solution. These techniques mainly differ in the way the source space is constructed and the cost function that is minimized to get an optimal solution. \n",
        "\n",
        "### The single dipole fit\n",
        "In this case, the inverse problem involves the estimation of a single dipolar source given the lead field matrix at each location inside the gray matter and the measured electrode potentials.  The inverse problem is an optimization problem where the Residual Energy (RE) cost function is minimized:\n",
        "\n",
        "\\begin{equation*}\n",
        "{\\left\\|\\mathbf{V}_{in}-\\mathbf{V}_{dipole}(\\mathbf{d(\\mathbf{r})})\\right\\|}\n",
        "\\label{eq:single_dipole_fit} \\tag{4}\n",
        "\\end{equation*}\n",
        "\n",
        "with $\\mathbf{V}_{in} \\in \\mathbb{R}^{K \\times 1}$ the electrode potentials measured at the scalp and $\\mathbf{V}_{dipole} \\in \\mathbb{R}^{K \\times 1}$  the electrode potentials caused by a single dipole calculated based on the forward model explained in equation $\\eqref{eq:sd}$.  This comes down to finding the dipole position corresponding with the minimal Relative Residual Energy.\n",
        "\n",
        "### Multiple dipole fit with MUSIC (Multiple Signal Classification)\n",
        "\n",
        "The multiple signal classification (MUSIC) algorithm can be used to locate multiple asynchronous dipolar sources (see Eq. $\\eqref{eq:md}$) through a three-dimensional (3D) head volume and computes projections onto an estimated signal subspace. To locate the sources, the user must search the head volume for multiple local peaks in the projection metric. We did not include the mathematecial details but for more details see [<cite>[1]</cite>](https://journals.lww.com/clinicalneurophys/Fulltext/1999/05000/EEG_Source_Localization_and_Imaging_Using_Multiple.4.aspx?casa_token=KlOVSMWVcPkAAAAA:DEuP4b3D5_SqXNTWC8qxBlEDsWCY7nh19Rlgo71ukB08-zC_y2yVr6gxXlrPAXEL0Se24bPr-vkDeho38OXoc9N_RxVAaUJh). \n",
        "\n",
        "### Distributed dipole solutions\n",
        "\n",
        "Because of the number of distributed sources is much higher (typically more than 1000) than the number of EEG channels (typically around 100), we need to add prior information to find a unique solution to Eq.$\\eqref{eq:dd}$. There are different techniques that allow this, such as the weighted minimum norm (WMN) solution: \n",
        "\n",
        "\\begin{equation*}\n",
        "\\begin{aligned}\n",
        "\\widehat{D} = \\min_{{D}}(||{{C}_{{\\epsilon}}}^{-1/2}({L}{D} - {V})||^2 + \\lambda||{WD}||^2) \\\\\n",
        "\\end{aligned} \\tag{5}\n",
        "\\end{equation*}\n",
        "\n",
        "This approach implicates minimizing an energy function, with ${{C}_{{\\epsilon}}}$ the prior covariance of the sensor noise, $W$ a weighting matrix including prior information of the source activity and with $\\lambda$ a hyperparameter that tunes the relative importance of the accuracy of the model $||{{C}_{{\\epsilon}}}^{-1/2}({L}{D} - {V})||^2$, and the regularisation term $||{WJ}||^2$\n",
        "\n",
        "Also other techniques can be used like LORETA, beamformers [<cite>[2]</cite>](https://ieeexplore.ieee.org/abstract/document/623056?casa_token=fbxhxZ4GUAkAAAAA:-JKpZ3R_mz2f2EmVQs85wIbjr-wP3iQuO-PX3py7-XLxIj-wMfRWBUSLzGCWGFx_ryFtLJnR), ...."
      ],
      "id": "67e6711a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e78bc5fe"
      },
      "source": [
        "## Part 1: Influence of the head model: 3-layered versus 4-layered head models\n",
        "\n",
        "In this section we will investigate the influence of using different head models based on a single dipole source model. We will assess the influence of modeling cerebrospinal fluid (CSF) in the head model. We will consider a 3-layered model consisting of a scalp, skull and brain compartment and a 4-layered having a scalp, skull, CSF and brain compartment. The 3- and 4-layered models can be found in hm_3lay.pickle and hm_4lay.pickle respectively. \n",
        "\n",
        "In task 1, we will investigate how the scalp topography changes for superficial and deep dipoles. In task 2, we will simulate data based on the 4-layered model and investigate the localization error made by assuming the more simple 3-layered model. Finally, in task 3 we will perform source localization on a real epileptic spike and compare the localization with the resected region that rendered the patient seizure free. "
      ],
      "id": "e78bc5fe"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f44d971c"
      },
      "source": [
        "<div class=\"alert alert-info\">\n",
        "    \n",
        "During this practical session, different images will be plotted. For some of these images, you need to use the inline backend, for others the notebook backend of matplotlib. It is indicated in the code when you need to switch. When handing in the notebook, make sure that all images are visible. You might need to re-run some cells to achieve this."
      ],
      "id": "f44d971c"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8amMQ7wXyX3k"
      },
      "source": [
        "!pip install nilearn\n",
        "!pip install niwidgets\n",
        "!pip install mne\n",
        "!pip install numpy\n",
        "!pip install nibabel"
      ],
      "id": "8amMQ7wXyX3k",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vis5tzgn1Hty"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "Vis5tzgn1Hty",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bc165b7"
      },
      "source": [
        "from nilearn import plotting\n",
        "from niwidgets import NiftiWidget"
      ],
      "id": "8bc165b7",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cf6a2e48"
      },
      "source": [
        "import pickle as P\n",
        "import mne\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import nilearn\n",
        "import matplotlib.pyplot as plt"
      ],
      "id": "cf6a2e48",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f70485cb"
      },
      "source": [
        "def SliceBrowser(path_to_image):\n",
        "    \n",
        "    image = NiftiWidget(path_to_image)\n",
        "    image.nifti_plotter(colormap = 'gray')\n",
        "    \n",
        "    return image"
      ],
      "id": "f70485cb",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0cf06d4"
      },
      "source": [
        "### Task 1.1\n",
        "\n",
        "Load **hm_3lay.pickle** and  **hm_4lay.pickle**. \n",
        "\n",
        "Explore the structures of hm_3lay and hm_4lay. \n",
        "\n",
        "Use the **.keys()** function to check that the structure consists of six fields, namely MRI, segmentation, conductivities, elec, dipole_loc, and forward_solution. "
      ],
      "id": "d0cf06d4"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1a46d186"
      },
      "source": [
        "three = P.load(open('.\\Part1\\Task_1_2\\hm_3lay.pickle', 'rb')) \n",
        "four =  P.load(open('.\\Part1\\Task_1_2\\hm_4lay.pickle', 'rb'))"
      ],
      "id": "1a46d186",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "1a98a935",
        "outputId": "7ab1f849-4e5f-4d9e-d6a0-cbf66886fae9"
      },
      "source": [
        "T = three.keys()\n",
        "F = four.keys()\n",
        "\n",
        "print(T)\n",
        "print(F)"
      ],
      "id": "1a98a935",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['MRI', 'segmentation', 'conductivities', 'elec', 'dipole_loc', 'forward_solution'])\n",
            "dict_keys(['MRI', 'segmentation', 'conductivities', 'elec', 'dipole_loc', 'forward_solution'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c758c126",
        "outputId": "076846e7-0669-44cd-f6e3-aaf415b38a1c"
      },
      "source": [
        "Th = len(three.get('conductivities'))\n",
        "Th3 = three.get('conductivities')\n",
        "print(Th)\n",
        "print(Th3)\n",
        "\n",
        "Fr = len(four.get('conductivities'))\n",
        "Fr4 = four.get('conductivities')\n",
        "print(Fr)\n",
        "print(Fr4)"
      ],
      "id": "c758c126",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n",
            "[0.33  0.022 0.33 ]\n",
            "4\n",
            "[0.33  0.022 0.33  1.79 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c39febc"
      },
      "source": [
        "<div class=\"alert alert-info\">\n",
        "    \n",
        "**Question:** What is the main difference between both models?\n",
        "    \n",
        "Type your anser in the green box below."
      ],
      "id": "7c39febc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4009dcb"
      },
      "source": [
        "<div class=\"alert alert-success\">\n",
        "<span style=\"color:black\">\n",
        "\n",
        "**Answer:** \n",
        "\n",
        "Each dictionary has been constructed based on the data each file, which constitute each item, has, and they have the same size with same amount of data.\n",
        "\n",
        "Considering the name of the files themselve, on each file the segmented layers are different (three on the first and four on the second), which affect the E/M properties of the head and the recorded coordinates of the geometry. Therefore, as could be seen above, the number of lists in conductivites as an example was recorded with one extra attributed respectively to the number of layers are being modeled.\n",
        "    \n",
        "</span>"
      ],
      "id": "f4009dcb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b768a2be"
      },
      "source": [
        "### Task 1.2\n",
        "\n",
        "The fields hm_3lay.MRI and hm_4lay.MRI contain the path to the anatomical MRI of the subject. \n",
        "\n",
        "Take a look at the MRI by using the function **SliceBrowser(path_to_image)**.\n",
        "\n",
        "In hm_3lay.segmentation and hm_4lay.segmentation, the path to the segmentation of the different tissues is given. \n",
        "\n",
        "Investigate the difference between the 3-layered and 4-layered segmentations (again) using the SliceBrowser function. \n",
        "\n",
        "Based on the subject’s MRI, make a figure in which you display a sagittal section containing the left lateral ventricle. Show how the tissues are segmented in the same slice in both models. Indicate below the conductivity value corresponding with the different tissue classes."
      ],
      "id": "b768a2be"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfc3efac"
      },
      "source": [
        "<div class=\"alert alert-success\">\n",
        "<span style=\"color:black\">\n",
        "\n",
        "**Used coordinates for section:**\n",
        "    \n",
        "* x = \n",
        "* y = \n",
        "* z = \n",
        "    \n",
        "**Conductivities 3-layered model:**\n",
        "\n",
        "* Layer 1 = ..., Condictivity value = ... S/m \n",
        "* Layer 2 = ..., Condictivity value = ...\n",
        "* ...\n",
        "    \n",
        "**Conductivities 4-layered model:**\n",
        "\n",
        "* Layer 1 = ..., Condictivity value = ...\n",
        "* Layer 2 = ...\n",
        "    \n",
        "</span>"
      ],
      "id": "dfc3efac"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b84ab683"
      },
      "source": [
        "%matplotlib inline"
      ],
      "id": "b84ab683",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aea959d"
      },
      "source": [
        "MRI3 = SliceBrowser('.\\Part1\\Task_1_2\\MRI_3lay.nii')\n",
        "plot(MRI3)\n",
        "MRI4 = SliceBrowser('.\\Part1\\Task_1_2\\MRI_4lay.nii')\n",
        "plot(MRI4)"
      ],
      "id": "5aea959d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aa38916e",
        "outputId": "55d00d84-7169-498c-f689-beac1d640dc1"
      },
      "source": [
        "Seg3 = SliceBrowser('.\\Part1\\Task_1_2\\segmentation_3lay.nii')\n",
        "plot(Seg3)\n",
        "Seg4 = SliceBrowser('.\\Part1\\Task_1_2\\segmentation_4lay.nii')\n",
        "plot(Seg4)"
      ],
      "id": "aa38916e",
      "execution_count": null,
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'NiftiWidget' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-75-2cd622c9e4e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mSeg3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSliceBrowser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.\\Part1\\Task_1_2\\segmentation_3lay.nii'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSeg3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mSeg4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSliceBrowser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.\\Part1\\Task_1_2\\segmentation_4lay.nii'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSeg4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<ipython-input-71-255e5460c2d5>\u001b[0m in \u001b[0;36mSliceBrowser\u001b[1;34m(path_to_image)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mSliceBrowser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_to_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNiftiWidget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_to_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnifti_plotter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolormap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'gray'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'NiftiWidget' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d032a33f",
        "outputId": "10091442-2bd6-4ab1-c4f8-986fbc95a919"
      },
      "source": [
        "fig = plt.figure();\n",
        "fig.clf()\n",
        "\n",
        "Sagital = fig.add_subplot(111)\n",
        "#Sagital.plot(T, x, marker='*', markerfacecolor='red', markersize=10)\n",
        "\n",
        "plt.title('Sagittal section of the left lateral ventricle')\n",
        "#plt.ylabel('Signal')\n",
        "#plt.xlabel('Time (s)')\n",
        "\n",
        "plt.minorticks_on()\n",
        "plt.grid(b=True, which='major', color='gray', lw=0.7)\n",
        "plt.grid(b=True, which='minor', color='grey', lw=0.5)\n",
        "plt.tick_params(axis='both', direction='out', length=6, width=2, labelcolor='b', colors='r')\n",
        "plt.show()"
      ],
      "id": "d032a33f",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6c932c7"
      },
      "source": [
        "### Task 1.3\n",
        "\n",
        "In both head models the same 62 electrodes setup is used. In the field 'elec', the labels and positions of the electrodes can be found. Visualize the electrode setup in 3D by 1) creating a MNE-montage and 2) plotting it. Take a look at the following pages in the MNE documentation: [make_dig_montage](https://mne.tools/stable/generated/mne.channels.make_dig_montage.html#mne.channels.make_dig_montage) and [DigMontage.plot](https://mne.tools/stable/generated/mne.channels.DigMontage.html#mne.channels.DigMontage.plot) to help you further: create a dictionary for the ch_pos-argument and set the coordinate-frame to mri. All other arguments can be ignored. "
      ],
      "id": "a6c932c7"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c750aaaa"
      },
      "source": [
        "mne.channels.make_dig_montage()"
      ],
      "id": "c750aaaa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82200e53"
      },
      "source": [
        "%matplotlib notebook\n"
      ],
      "id": "82200e53",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f159f0b2"
      },
      "source": [
        "### Task 1.4\n",
        "\n",
        "The field dipole_loc corresponds to the locations of the dipoles. All dipoles are chosen within the brain compartment. To visualize the locations of the dipoles using the SliceBrowser-function, create a new matrix with the same dimensions as the MRI array and with ones on the locations of the dipoles. We have given you the code to convert the dipole locations to indices in the matrix below.\n",
        "\n",
        "Once you have the matrix with the dipoles, convert it to an .nii image using: \n",
        "\n",
        "    image = nib.Nifti1Image(matrix, affine = None)\n",
        "    \n",
        "With the function SliceBrowser(image) you can subsequently browse through the slices to see where the dipoles are located in the brain. What is the spacing between the dipoles knowing that the voxel dimensions of the MRI-matrix are 1 × 1 × 1 mm?\n",
        "\n"
      ],
      "id": "f159f0b2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a7ef94d"
      },
      "source": [
        "<div class=\"alert alert-info\">\n",
        "    \n",
        "**Question:** What is the spacing between the dipoles knowing that the voxel dimentsions are 1 x 1 x 1 mm?\n",
        "    \n",
        "Type your anser in the green box below."
      ],
      "id": "6a7ef94d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bf9d3de"
      },
      "source": [
        "<div class=\"alert alert-success\">\n",
        "<span style=\"color:black\">\n",
        "\n",
        "**Answer:** \n",
        "    \n",
        "</span>"
      ],
      "id": "0bf9d3de"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0e9fc270"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "# Make sure that MRI = SliceBrowser(hm_3lay['MRI'])\n",
        "MRI_array = MRI.data.get_data()\n",
        "inverse = np.linalg.inv(MRI.data.affine)\n",
        "\n",
        "# The line below gives you the dipole locations in matrix indices\n",
        "# 1. Make sure that the dipole locations are in mm instead of m, 2. apply the inverse transformation matrix, \n",
        "# 3. convert to integers\n",
        "dipole_locs = np.array([np.floor(nib.affines.apply_affine(inverse, d)).astype(int) for d in hm_3lay['dipole_loc']['pos']*1e03])\n",
        "\n",
        "\n",
        "# Create a new matrix with the same dimensions as MRI_array\n",
        "\n",
        "\n",
        "# Fill matrix with ones on locations of dipoles\n",
        "\n",
        "\n",
        "# Convert matrix to Nifti1Images and plot\n",
        "\n"
      ],
      "id": "0e9fc270",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dd7362b"
      },
      "source": [
        "### Task 1.5\n",
        "\n",
        "In the field 'forward_solution', the path towards an MNE-object of the type 'Forward' is given. Load these objects for the 3-layered and 4-layered models using the [mne.read_forward_solution()](https://mne.tools/stable/generated/mne.read_forward_solution.html)-function. Use the .keys()-function to get an idea of the content of this object. The leadfield matrices corresponding with the dipoles can be found under the 'sol'-key, in the field data.\n",
        "\n",
        "Assuming that the number of electrodes is K and the number of dipoles is equal to N, the leadfield matrix is a K x 3N matrix. Each element in the matrix links the unit current on the position of the dipole in x, y or z-orientation with the voltage potential that is measured at an electrode. "
      ],
      "id": "4dd7362b"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63c2dabc"
      },
      "source": [
        "<div class=\"alert alert-info\">\n",
        "    \n",
        "**Question:** What is the shape of the leadfield matrix?\n",
        "    \n",
        "Type your anser in the green box below."
      ],
      "id": "63c2dabc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bcf72b8"
      },
      "source": [
        "<div class=\"alert alert-success\">\n",
        "<span style=\"color:black\">\n",
        "\n",
        "**Answer:** \n",
        "    \n",
        "</span>"
      ],
      "id": "7bcf72b8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0f5dbeec"
      },
      "source": [
        ""
      ],
      "id": "0f5dbeec",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06f09937"
      },
      "source": [
        ""
      ],
      "id": "06f09937",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2b947c8d"
      },
      "source": [
        "### Task 1.6\n",
        "\n",
        "The code below can be used to calculate the voltage potentials at the electrodes that correspond to a unit dipole with z-orientation at index 3000 for the 3-layered head model (remember Eq. (1)?). You can use the function [plot_topomap()](https://mne.tools/stable/generated/mne.Evoked.html#mne.Evoked.plot_topomap) to depict the scalp map of this. Do the same thing using the 4-layered model. \n",
        "\n",
        "<div class=\"alert alert-info\">\n",
        "    \n",
        "**Question:** How do the scalp maps differ between the 3-layered and 4-layered head model at this position? You can investigate this by calculating the difference between both evoked potentials:\n",
        "    \n",
        "    mne.combine_evoked([evoked_1, evoked_2], weights=[...]))\n",
        "    \n",
        "and plotting this difference again using the plot_topomap-function.\n",
        "    \n",
        "**Question 2:** Also make a figure depicting the difference between the scalp maps for a unit dipole with orientation [1 1 -0.5] at indices 49232 and 28532. Where are these dipoles located? What can you conclude from this? What is the difference in neglecting the CSF for both dipole locations?"
      ],
      "id": "2b947c8d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "605dd169"
      },
      "source": [
        "<div class=\"alert alert-success\">\n",
        "<span style=\"color:black\">\n",
        "\n",
        "**Answer:** \n",
        "\n",
        "    \n",
        "</span>"
      ],
      "id": "605dd169"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0ac2f9a"
      },
      "source": [
        "def evoked_from_dipole(dipole_index, dipole_orientation, fwd, electrode_labels, sfreq = 256):\n",
        "    \n",
        "    data = np.zeros((fwd['nsource'], 3, 1))\n",
        "    data[dipole_index, :, 0] = np.array(dipole_orientation)*1e-09\n",
        "\n",
        "    dipole = mne.VolVectorSourceEstimate(data, vertices = [np.arange(0, fwd['nsource'])], tmin = 0, tstep = 1./sfreq)\n",
        "\n",
        "    info = mne.create_info(electrode_labels, sfreq, 'eeg').set_montage(montage)\n",
        "    evoked = mne.apply_forward(fwd, dipole, info)\n",
        "    \n",
        "    return evoked"
      ],
      "id": "f0ac2f9a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15753b52"
      },
      "source": [
        "evoked_3lay = evoked_from_dipole(3000, [0., 0., 1.], fwd_3lay, electrode_labels)\n",
        "..."
      ],
      "id": "15753b52",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "701634cc"
      },
      "source": [
        ""
      ],
      "id": "701634cc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "646d716a"
      },
      "source": [
        ""
      ],
      "id": "646d716a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "260bdaf2"
      },
      "source": [
        ""
      ],
      "id": "260bdaf2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8b89c87d"
      },
      "source": [
        "### Task 2.1 \n",
        "\n",
        "In the previous task, we already investigated the difference in scalp maps between the 3-layered and 4-layered model. Now we will determine the localization error made by not modeling the CSF.\n",
        "\n",
        "Simulate EEG as before using the leadfield matrices of the 4-layered model (not the 3-layered model!) at a dipole position close to the center of the brain and the dipole closest to O2. Use the coordinates of both the dipoles and the electrodes to find the correct dipole indices. Consider a unit dipole in [1 1 1] orientation at one time point. \n",
        "\n",
        "Perform a dipole fit on the generated EEG sample using the function:\n",
        "\n",
        "    dipole, residual = mne.beamformer.rap_music(evoked, fwd, noise_cov = noise_cov, n_dipoles=1, return_residual=True, verbose=False)\n",
        "\n",
        "for both the 3-layered and 4-layered head model. For each of the obtained dipoles, look at the location, the orientation and the goodness of fit (see <a href=\"https://mne.tools/stable/generated/mne.Dipole.html\" target=\"_blank\">this link</a> for more info). \n",
        "\n",
        "<div class=\"alert alert-info\">\n",
        "    \n",
        "**Question:** What are the coordinates of the dipole closest to the center of the brain and of the one closest to O2?\n",
        "    \n",
        "**Question 2:** Give the location, the orientation and the goodness of fit for each of the obtained dipoles. Explain."
      ],
      "id": "8b89c87d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c47cc4e"
      },
      "source": [
        "<div class=\"alert alert-success\">\n",
        "<span style=\"color:black\">\n",
        "\n",
        "**Answer:**\n",
        "    \n",
        "* Closest to center: \n",
        "* Closest to O2: \n",
        "    \n",
        "**Answer 2:**\n",
        "    \n",
        "   |               | Coordinates| Orientation| GOF   |\n",
        "|:-----------------|:-----------|:-----------|:------|\n",
        "| Center 3-layered | [x, y, z]  | [...]  | % |\n",
        "| Center 4-layered | [x, y, z]  | [...]  | % |\n",
        "| O2 3-layered | [x, y, z]  | [...] | % |\n",
        "| O2 4-layered | [x, y, z] | [...]  | % |\n",
        "    \n",
        "</span>"
      ],
      "id": "7c47cc4e"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cbab06f"
      },
      "source": [
        "noise_cov = mne.make_ad_hoc_cov(info, std=1e-06, verbose=None)"
      ],
      "id": "4cbab06f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7814c0c"
      },
      "source": [
        ""
      ],
      "id": "e7814c0c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42751950"
      },
      "source": [
        ""
      ],
      "id": "42751950",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "346c4ab8"
      },
      "source": [
        "### Task 2.2\n",
        "\n",
        "<div class=\"alert alert-info\">\n",
        "    \n",
        "**Question:** Calculate the localization error for each dipole for both head models. Discuss where the error is the largest when not modeling CSF."
      ],
      "id": "346c4ab8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "567ce82d"
      },
      "source": [
        "<div class=\"alert alert-success\">\n",
        "<span style=\"color:black\">\n",
        "\n",
        "**Answer:**\n",
        "    \n",
        "|               | Localisation error | \n",
        "|:-----------------|-----------|\n",
        "| Center 3-layered |  |\n",
        "| Center 4-layered |   |\n",
        "| O2 3-layered |  |\n",
        "| O2 4-layered |  |\n",
        "    \n",
        "</span>"
      ],
      "id": "567ce82d"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cdd6a99"
      },
      "source": [
        ""
      ],
      "id": "6cdd6a99",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4042d27"
      },
      "source": [
        ""
      ],
      "id": "c4042d27",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bbaa7bc"
      },
      "source": [
        "### Task 3.1\n",
        "\n",
        "In this exercise, ESI will be applied to a case-study of epilepsy. Epilepsy is a neurological disorder characterized by recurrent seizures. These seizures are associated with aberrant EEG signals since neurons start to fire hypersynchronously in certain brain regions. However, in the EEG, epilepsy is not only characterized by seizures. Also in between seizures, when the patient has no clinical symptoms of a seizure, and can function normally, short epileptic events happen. These events are called interictal epileptiform discharges (IEDs). One type of IED is the spike. A spike is generated somewhere in the brain, and localization of these spikes may help the neurologists on deciding where in the brain the epilepsy is coming from. In this exercise, you will see what spikes are and you will localize them."
      ],
      "id": "3bbaa7bc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d82bb48e"
      },
      "source": [
        "Load hm_epi.pickle as before and investigate the structure.\n",
        "\n",
        "<div class=\"alert alert-info\">\n",
        "    \n",
        "**Question:** Describe the difference between this head model and the 4-layered model.\n",
        "    \n",
        "Type your anser in the green box below."
      ],
      "id": "d82bb48e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbd52232"
      },
      "source": [
        "<div class=\"alert alert-success\">\n",
        "<span style=\"color:black\">\n",
        "\n",
        "**Answer:** \n",
        "    \n",
        "    \n",
        "</span>"
      ],
      "id": "dbd52232"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "980afe0d"
      },
      "source": [
        "with open('./Part1/Task_3/hm_epi.pickle', 'rb') as handle:\n",
        "    hm_epi = pickle.load(handle)"
      ],
      "id": "980afe0d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8461db9c"
      },
      "source": [
        ""
      ],
      "id": "8461db9c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ed7859a"
      },
      "source": [
        ""
      ],
      "id": "1ed7859a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d384b10e"
      },
      "source": [
        "### Task 3.2\n",
        "\n",
        "The file spikes-epo.fif contains the EEG of 35 spikes marked by the neurologist. The data in this [Epochs](https://mne.tools/stable/generated/mne.Epochs.html)-object is a 35 x K x T matrix in which T is the number of samples, K the number of electrodes and 35 the number of spikes. The sampling frequency is equal to 256 Hz. Plot the spikes.\n",
        "\n",
        "Make an average spike, plot it (you can use the default .plot()-function) and investigate the scalp map (.plot_topomap(times=\\[x\\]) at the time of the peak. \n",
        "\n",
        "<div class=\"alert alert-info\">\n",
        "    \n",
        "**Question:** What does this scalp map tell us?\n",
        "    \n",
        "Type your anser in the green box below."
      ],
      "id": "d384b10e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21e80e17"
      },
      "source": [
        "<div class=\"alert alert-success\">\n",
        "<span style=\"color:black\">\n",
        "\n",
        "**Answer:** \n",
        "    \n",
        "</span>"
      ],
      "id": "21e80e17"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14b4010c"
      },
      "source": [
        "spikes = mne.read_epochs('./Part1/Task_3/spikes-epo.fif', verbose=0)\n",
        "print(spikes.get_data().shape)"
      ],
      "id": "14b4010c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "54fd103b"
      },
      "source": [
        "%matplotlib notebook\n",
        "\n"
      ],
      "id": "54fd103b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8a0754e9"
      },
      "source": [
        ""
      ],
      "id": "8a0754e9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fea1f7af"
      },
      "source": [
        ""
      ],
      "id": "fea1f7af",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5c8cc7bf"
      },
      "source": [
        "### Task 3.3\n",
        "\n",
        "Load the forward-solution and perform dipole localization at 3 time points: the beginning of the spike, the peak of the spike and the 50% rise-time of the spike (the center between the peak and start of the spike). To do this, make a copy of the average spike and use the .crop(t1, t2)-function to crop the object to 1 time-point by setting t1=t2. Plot the locations of the dipoles using the plot_dipoles()-function given below.\n",
        "\n",
        "<div class=\"alert alert-info\">\n",
        "    \n",
        "**Question:** How does the dipole location vary over time? Which time point gives the best data fit?\n",
        "    \n",
        "Type your anser in the green box below."
      ],
      "id": "5c8cc7bf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a449d4a"
      },
      "source": [
        "<div class=\"alert alert-success\">\n",
        "<span style=\"color:black\">\n",
        "\n",
        "**Answer:** \n",
        "    \n",
        "|               | Time | Coordinates| Orientation| GOF   |\n",
        "|:-----------------|:-------|:-----------|:-----------|:------|\n",
        "| Start |  |[x, y, z]  | [...]  | % |\n",
        "| 50%-rise |  |[x, y, z]  | [...]  | % |\n",
        "| Peak |  |[x, y, z]  | [...] | % |\n",
        "    \n",
        "</span>"
      ],
      "id": "8a449d4a"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "031eca7b"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "def plot_dipoles(dipoles, path_to_MRI):\n",
        "\n",
        "    for dip in dipoles:\n",
        "\n",
        "        fig = plotting.plot_anat(path_to_MRI, cut_coords = dip.pos[0] * 1e03)\n",
        "        marker_coords = [dip.pos[0] * 1e03]\n",
        "        fig.add_markers(marker_coords, marker_color='r', marker_size=30)"
      ],
      "id": "031eca7b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a25ea941"
      },
      "source": [
        ""
      ],
      "id": "a25ea941",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c49f6caa"
      },
      "source": [
        ""
      ],
      "id": "c49f6caa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "342ad60d"
      },
      "source": [
        ""
      ],
      "id": "342ad60d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bfcb976"
      },
      "source": [
        "The file resected_zone.nii contains a mask of the resected zone. Look at the resected zone using:\n",
        "    \n",
        "    plotting.view_img(path_to_resected_zone, path_to_MRI, colorbar = False)\n",
        "    \n",
        "Which of the dipoles is located closest to the resected zone? To answer this, calculate the distance between each of the dipoles and the center of the resected zone. Use the function \n",
        "\n",
        "    calculate_center_of_mass(path_to_mask)\n",
        "    \n",
        "to get the center of mass.\n",
        "\n",
        "<div class=\"alert alert-info\">\n",
        "    \n",
        "**Question:** When do we get the best source localization compared with the resected region? Can you explain why?\n",
        "    \n",
        "Type your anser in the green box below."
      ],
      "id": "7bfcb976"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3905673b"
      },
      "source": [
        "<div class=\"alert alert-success\">\n",
        "<span style=\"color:black\">\n",
        "\n",
        "**Answer:**\n",
        "    \n",
        "* Distance start: \n",
        "* Distance mid: \n",
        "* Distance peak: \n",
        "    \n",
        "</span>"
      ],
      "id": "3905673b"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71e609e3"
      },
      "source": [
        "from scipy import ndimage\n",
        "\n",
        "def calculate_center_of_mass(path_to_mask):\n",
        "    \n",
        "    resected_zone_array = nilearn._utils.niimg.load_niimg(resected_zone_path).get_data()\n",
        "    affine = nilearn._utils.niimg.load_niimg(resected_zone_path).affine\n",
        "    center = np.round(ndimage.measurements.center_of_mass(resected_zone_array))\n",
        "    \n",
        "    #convert to m instead of mm to have mne-coordinates\n",
        "    center = nib.affines.apply_affine(affine, center)*1e-03\n",
        "    \n",
        "    return center"
      ],
      "id": "71e609e3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c79eb010"
      },
      "source": [
        ""
      ],
      "id": "c79eb010",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34da7759"
      },
      "source": [
        ""
      ],
      "id": "34da7759",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96e1fca6"
      },
      "source": [
        ""
      ],
      "id": "96e1fca6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8f6371db"
      },
      "source": [
        "***\n",
        "## Part 2: Reconstruction of realistic ERP data\n",
        "\n",
        "In this final task, we will reconstruct real ERP data recorded in 20 different subjects based on different inverse techniques. In brief, twenty healthy individuals performed 150 trials of faces stimuli. The EEG data were collected from 83 EEG electrodes using a BrainAmp system (BrainProducts, Gilching, Germany). To extract task-related ERPs, the data were then segmented from 100 ms before until 500 ms after stimulus onset, and baseline corrected. Finally, the data were averaged over trials and subjects and average referenced resulting in a grand average ERP dataset corresponding with faces stimuli. In task 1, we will evaluate the ERP data and check which activity in particular we want to reconstruct. In task 2 we will reconstruct the ERP data based on a single dipole model and a multiple dipole model.\n",
        "\n",
        "### Task 1.1\n",
        "\n",
        "<div class=\"alert alert-info\">\n",
        "Load ERP_faces-ave.fif. This is the ERP data in a window starting from -100 ms to 500 ms. Plot this ERP. \n",
        "    \n",
        "**Question:** What can you see?"
      ],
      "id": "8f6371db"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dc4d8cc"
      },
      "source": [
        "<div class=\"alert alert-success\">\n",
        "<span style=\"color:black\">\n",
        "\n",
        "**Answer:** \n",
        "    \n",
        "</span>"
      ],
      "id": "5dc4d8cc"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1781028b"
      },
      "source": [
        "%matplotlib notebook\n",
        "\n",
        "ERP = mne.read_evokeds('./Part2/ERP_faces-ave.fif')[0].set_eeg_reference('average')\n"
      ],
      "id": "1781028b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "db85b766"
      },
      "source": [
        "### Task 1.2\n",
        "\n",
        "Check out the activity around 170 ms after stimulus. \n",
        "\n",
        "We will reconstruct the activity at the time of the peak. Select the peak by cropping the ERP data, and plot the topomap."
      ],
      "id": "db85b766"
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "565ab394"
      },
      "source": [
        ""
      ],
      "id": "565ab394",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6a04f25d"
      },
      "source": [
        ""
      ],
      "id": "6a04f25d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a2f3382"
      },
      "source": [
        "### Task 2.1\n",
        "\n",
        "Based on the fragment N170 you selected in the previous task we will now reconstruct the data using a single dipole and a multiple dipole source model.\n",
        "\n",
        "<div class=\"alert alert-info\">\n",
        "Read the forward solution 'hm_erp-fwd.fif'. Reconstruct the N170 using a single dipole and plot this dipole using the plot_dipoles()-function from before. You can use the 'T1.mgz'-file as MRI. \n",
        "    \n",
        "**Question**: What is the GOF of this dipole and where is the dipole located?"
      ],
      "id": "7a2f3382"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7d6b455"
      },
      "source": [
        "<div class=\"alert alert-success\">\n",
        "<span style=\"color:black\">\n",
        "\n",
        "**Answer:** \n",
        "    \n",
        "</span>"
      ],
      "id": "a7d6b455"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c91fa4a8"
      },
      "source": [
        ""
      ],
      "id": "c91fa4a8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44a137c1"
      },
      "source": [
        ""
      ],
      "id": "44a137c1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c11262fa"
      },
      "source": [
        ""
      ],
      "id": "c11262fa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41bf71d5"
      },
      "source": [
        "<div class=\"alert alert-info\">\n",
        "\n",
        "We will now use a distributed dipole approach to reconstruct the N170. To do this, use the code given below. \n",
        "    \n",
        "**Question**: Where is the activity located?"
      ],
      "id": "41bf71d5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c29a77fc"
      },
      "source": [
        "<div class=\"alert alert-success\">\n",
        "<span style=\"color:black\">\n",
        "\n",
        "**Answer:** \n",
        "    \n",
        "</span>"
      ],
      "id": "c29a77fc"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75b5bfe5"
      },
      "source": [
        "noise_cov = mne.make_ad_hoc_cov(N170.info)\n",
        "inverse = mne.minimum_norm.make_inverse_operator(N170.info, fwd, noise_cov, verbose = 0)\n",
        "\n",
        "stc = mne.minimum_norm.apply_inverse(N170.set_eeg_reference(projection = True), \n",
        "                                     inverse, method='sLORETA', lambda2 = 0.1, verbose = 0)\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "brain = stc.plot(subjects_dir = './Part2/subjects_freesurfer', subject = 'ERP', src = fwd['src'], \n",
        "                 hemi = 'lh', views='med', surface = 'white', backend = 'matplotlib')\n",
        "\n",
        "brain = stc.plot(subjects_dir = './Part2/subjects_freesurfer', subject = 'ERP', src = fwd['src'], \n",
        "                 hemi = 'rh', views='med', surface = 'white', backend = 'matplotlib')"
      ],
      "id": "75b5bfe5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "663458b7"
      },
      "source": [
        ""
      ],
      "id": "663458b7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7b15eed7"
      },
      "source": [
        "### Task 2.3\n",
        "\n",
        "<div class=\"alert alert-info\">\n",
        "\n",
        "**Question**: What do you notice? What are the differences between the reconstructions? If you know the N170 component caused by faces stimuli is generated in the left and right fusiform face area mainly in the right hemisphere (see figure), which of the reconstructions would you prefer?\n",
        "    \n",
        "<img src=\"./Figures/FFA.gif\" alt=\"Fig 6\" width=\"300px\">\n",
        "\n"
      ],
      "id": "7b15eed7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4eb96ca"
      },
      "source": [
        "<div class=\"alert alert-success\">\n",
        "<span style=\"color:black\">\n",
        "\n",
        "**Answer:** \n",
        "    \n",
        "</span>"
      ],
      "id": "f4eb96ca"
    }
  ]
}